<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Push-Up Posture Prediction</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.21.0-dev.20241028-dd28f09ce2/dist/ort.min.js"></script>
    <script src="/frontend/js/check_pushup.js"></script>
    <style>
        body {
            display: block;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
        }
        video, canvas {
            border: 2px solid #ccc;
            border-radius: 8px;
            margin-bottom: 10px;
        }
    </style>
</head>
<body>
    <h1>Push-Up Posture Prediction</h1>
    <video id="video" autoplay playsinline width="640" height="480"></video>
    <canvas id="canvas" width="640" height="480"></canvas>
    <script type="module">
        // Get video and canvas elements
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');

        // Initialize MediaPipe Pose
        const pose = new Pose({
            locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`
        });
        pose.setOptions({
            modelComplexity: 1,
            smoothLandmarks: true,
            enableSegmentation: false,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5
        });

        const camera = new Camera(video, {
            onFrame: async () => {
                await pose.send({ image: video });
            },
            width: 640,
            height: 480
        });
        camera.start();

        // Draw landmarks and call predict
        pose.onResults(async (results) => {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

            // Draw pose landmarks
            if (results.poseLandmarks) {
                // Extract normalized landmarks as an array
                const landmarks = results.poseLandmarks.flatMap(l => [l.x, l.y, l.z]);

                // Convert frame to tensor for ONNX model
                const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                const imageTensor = tf.browser.fromPixels(imageData);

                try {
                  const a = await check_pushup(imageTensor, landmarks);
                  console.log(a);
                } catch (err) {
                    console.error('Prediction error:', err);
                }

                imageTensor.dispose();
            }
        });
    </script>
</body>
</html>
